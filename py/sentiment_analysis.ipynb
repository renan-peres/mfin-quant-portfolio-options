{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2977491",
   "metadata": {},
   "source": [
    "# Sentiment Analysis - `TextBlob`\n",
    "- FMP API Documentation: https://site.financialmodelingprep.com/developer/docs/stable/stock-news"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd6d8f6",
   "metadata": {},
   "source": [
    "### **Step 1: Import Libraries + Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22089611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "from typing import Dict, List\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Data manipulation libraries\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from pandas.tseries.offsets import BDay\n",
    "\n",
    "# API Requests\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "# Libraries for sentiment analysis\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def create_session():\n",
    "    \"\"\"Create a requests session with retry configuration\"\"\"\n",
    "    session = requests.Session()\n",
    "    retries = Retry(\n",
    "        total=3,\n",
    "        backoff_factor=1,\n",
    "        status_forcelist=[429, 500, 502, 503, 504]\n",
    "    )\n",
    "    session.mount('https://', HTTPAdapter(max_retries=retries, pool_maxsize=10))\n",
    "    return session\n",
    "\n",
    "def fetch_data(api_key: str, session: requests.Session, days_back: int = None, max_pages: int = None, records_per_page: int = None, request_timeout: int = None) -> Dict:\n",
    "    \"\"\"Fetch stock news with pagination\"\"\"\n",
    "    # Use parameters or fall back to default values\n",
    "    days_back = days_back if days_back is not None else 7\n",
    "    max_pages = max_pages if max_pages is not None else 10\n",
    "    records_per_page = records_per_page if records_per_page is not None else 1000\n",
    "    request_timeout = request_timeout if request_timeout is not None else 10\n",
    "    \n",
    "    # API base URL\n",
    "    API_BASE_URL = \"https://financialmodelingprep.com/api/v3/stock_news\"\n",
    "    \n",
    "    # Calculate date range\n",
    "    today = datetime.now().date()\n",
    "    week_ago = today - timedelta(days=days_back)\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    # Loop through max_pages with records_per_page records each\n",
    "    for page in range(max_pages):\n",
    "        url = API_BASE_URL\n",
    "        params = {\n",
    "            \"apikey\": api_key,\n",
    "            \"from\": week_ago.strftime('%Y-%m-%d'),\n",
    "            \"to\": today.strftime('%Y-%m-%d'),\n",
    "            \"limit\": records_per_page,\n",
    "            \"page\": page\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            print(f\"Fetching page {page + 1}/{max_pages}...\")\n",
    "            response = session.get(url, params=params, timeout=request_timeout)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            if not data:  # If no more data, break the loop\n",
    "                print(f\"No more data found at page {page + 1}. Stopping pagination.\")\n",
    "                break\n",
    "                \n",
    "            all_data.extend(data)\n",
    "            print(f\"Page {page + 1}: {len(data)} articles fetched\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching page {page + 1}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"Total articles fetched: {len(all_data)}\")\n",
    "    return all_data\n",
    "\n",
    "# ===============================================================================\n",
    "# SENTIMENT ANALYSIS FUNCTIONS\n",
    "# ===============================================================================\n",
    "\n",
    "def extract_stock_symbols(text, all_tickers=None, excluded_symbols=None):\n",
    "    \"\"\"Extract valid stock symbols from text, excluding common words\"\"\"\n",
    "    if all_tickers is None:\n",
    "        all_tickers = set()\n",
    "    if excluded_symbols is None:\n",
    "        excluded_symbols = {'AI', 'S', 'A', 'U', 'E', 'US', 'ET', 'TSXV', 'CODI', 'C'}\n",
    "    \n",
    "    symbols = re.findall(r'\\b[A-Z]{1,5}\\b', text)\n",
    "    return [symbol for symbol in symbols \n",
    "            if symbol in all_tickers and symbol not in excluded_symbols]\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    \"\"\"Analyze sentiment using TextBlob and classify as bullish/bearish/neutral\"\"\"\n",
    "    polarity = TextBlob(text).sentiment.polarity\n",
    "    \n",
    "    if polarity > 0.1:\n",
    "        return 'bullish', polarity\n",
    "    elif polarity < -0.1:\n",
    "        return 'bearish', polarity\n",
    "    else:\n",
    "        return 'neutral', polarity\n",
    "\n",
    "def calculate_stock_sentiment_metrics(df, all_tickers=None, excluded_symbols=None):\n",
    "    \"\"\"Calculate comprehensive sentiment metrics for each stock symbol\"\"\"\n",
    "    if all_tickers is None:\n",
    "        all_tickers = set()\n",
    "    if excluded_symbols is None:\n",
    "        excluded_symbols = {'AI', 'S', 'A', 'U', 'E', 'US', 'ET', 'TSXV', 'CODI', 'C'}\n",
    "    \n",
    "    stock_metrics = defaultdict(lambda: {\n",
    "        'sentiment_scores': [],\n",
    "        'bullish_count': 0,\n",
    "        'bearish_count': 0,\n",
    "        'neutral_count': 0,\n",
    "        'total_articles': 0\n",
    "    })\n",
    "    \n",
    "    # Process each news article\n",
    "    for row in df.iter_rows(named=True):\n",
    "        full_text = f\"{row.get('title', '')} {row.get('text', '')}\"\n",
    "        mentioned_symbols = extract_stock_symbols(full_text, all_tickers, excluded_symbols)\n",
    "        sentiment_type, sentiment_score = analyze_sentiment(full_text)\n",
    "        \n",
    "        # Update metrics for each mentioned symbol\n",
    "        for symbol in mentioned_symbols:\n",
    "            metrics = stock_metrics[symbol]\n",
    "            metrics['sentiment_scores'].append(sentiment_score)\n",
    "            metrics['total_articles'] += 1\n",
    "            metrics[f'{sentiment_type}_count'] += 1\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    final_metrics = {}\n",
    "    for symbol, data in stock_metrics.items():\n",
    "        if data['total_articles'] > 0:\n",
    "            total = data['total_articles']\n",
    "            avg_sentiment = sum(data['sentiment_scores']) / len(data['sentiment_scores'])\n",
    "            \n",
    "            final_metrics[symbol] = {\n",
    "                \"articlesInLastWeek\": total,\n",
    "                \"companyNewsScore\": round((avg_sentiment + 1) / 2, 4),\n",
    "                \"sentiment\": {\n",
    "                    \"bearishPercent\": round(data['bearish_count'] / total, 4),\n",
    "                    \"bullishPercent\": round(data['bullish_count'] / total, 4)\n",
    "                },\n",
    "                \"averageSentimentScore\": round(avg_sentiment, 4),\n",
    "                \"totalArticles\": total\n",
    "            }\n",
    "    \n",
    "    return final_metrics\n",
    "\n",
    "# ===============================================================================\n",
    "# SECTOR ANALYSIS & FUNDAMENTAL DATA INTEGRATION\n",
    "# ===============================================================================\n",
    "\n",
    "def calculate_sector_averages(sentiment_df, fundamentals_pandas):\n",
    "    \"\"\"Calculate sector-level sentiment averages\"\"\"\n",
    "    sector_metrics = defaultdict(list)\n",
    "    \n",
    "    for row in sentiment_df.iter_rows(named=True):\n",
    "        symbol = row['symbol']\n",
    "        if symbol in fundamentals_pandas.index:\n",
    "            sector = fundamentals_pandas.loc[symbol, 'Sector']\n",
    "            sector_metrics[sector].append({\n",
    "                'bullishPercent': row['bullishPercent'],\n",
    "                'newsScore': row['companyNewsScore']\n",
    "            })\n",
    "    \n",
    "    return {\n",
    "        sector: {\n",
    "            'sectorAverageBullishPercent': round(sum(m['bullishPercent'] for m in metrics) / len(metrics), 4),\n",
    "            'sectorAverageNewsScore': round(sum(m['newsScore'] for m in metrics) / len(metrics), 4)\n",
    "        }\n",
    "        for sector, metrics in sector_metrics.items() if metrics\n",
    "    }\n",
    "\n",
    "def get_fundamental_value(symbol, column, default=0):\n",
    "    \"\"\"Safely get fundamental data value for a symbol\"\"\"\n",
    "    # This function needs access to fundamentals_pandas from the calling scope\n",
    "    # We'll modify this to accept it as a parameter\n",
    "    import pandas as pd\n",
    "    try:\n",
    "        # Try to access the global fundamentals_pandas if it exists\n",
    "        import __main__\n",
    "        if hasattr(__main__, 'fundamentals_pandas'):\n",
    "            fundamentals_pandas = __main__.fundamentals_pandas\n",
    "            return fundamentals_pandas.loc[symbol, column] if symbol in fundamentals_pandas.index else default\n",
    "        else:\n",
    "            return default\n",
    "    except:\n",
    "        return default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074be0fb",
   "metadata": {},
   "source": [
    "### **Step 2: Extract News - FMP API Call**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0579c708",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "execution": {
     "iopub.execute_input": "2025-05-29T14:21:43.053055Z",
     "iopub.status.busy": "2025-05-29T14:21:43.052715Z",
     "iopub.status.idle": "2025-05-29T14:21:43.092204Z",
     "shell.execute_reply": "2025-05-29T14:21:43.091297Z"
    },
    "id": "0579c708",
    "outputId": "25413516-9768-4f80-a412-c58c4a59dbf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching page 1/15...\n",
      "Page 1: 998 articles fetched\n",
      "Fetching page 2/15...\n",
      "Page 2: 1000 articles fetched\n",
      "Fetching page 3/15...\n",
      "Page 3: 1000 articles fetched\n",
      "Fetching page 4/15...\n",
      "Page 4: 1000 articles fetched\n",
      "Fetching page 5/15...\n",
      "Page 5: 999 articles fetched\n",
      "Fetching page 6/15...\n",
      "Page 6: 999 articles fetched\n",
      "Fetching page 7/15...\n",
      "Page 7: 997 articles fetched\n",
      "Fetching page 8/15...\n",
      "Page 8: 1000 articles fetched\n",
      "Fetching page 9/15...\n",
      "Page 9: 1000 articles fetched\n",
      "Fetching page 10/15...\n",
      "Page 10: 1000 articles fetched\n",
      "Fetching page 11/15...\n",
      "Page 11: 1000 articles fetched\n",
      "Fetching page 12/15...\n",
      "Page 12: 999 articles fetched\n",
      "Fetching page 13/15...\n",
      "Page 13: 998 articles fetched\n",
      "Fetching page 14/15...\n",
      "Page 14: 1000 articles fetched\n",
      "Fetching page 15/15...\n",
      "Page 15: 1000 articles fetched\n",
      "Total articles fetched: 14990\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>symbol</th><th>publishedDate</th><th>title</th><th>image</th><th>site</th><th>text</th><th>url</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;MONRF&quot;</td><td>&quot;2025-06-02 11:17:33&quot;</td><td>&quot;Moncler: Growth, Low Debt, And…</td><td>&quot;https://images.financialmodeli…</td><td>&quot;seekingalpha.com&quot;</td><td>&quot;The DCF model implemented sugg…</td><td>&quot;https://seekingalpha.com/artic…</td></tr><tr><td>&quot;X&quot;</td><td>&quot;2025-06-02 11:15:19&quot;</td><td>&quot;Jobs Week Starts with More Tra…</td><td>&quot;https://images.financialmodeli…</td><td>&quot;zacks.com&quot;</td><td>&quot;Currently both the blue-chip D…</td><td>&quot;https://www.zacks.com/stock/ne…</td></tr><tr><td>&quot;CLCO&quot;</td><td>&quot;2025-06-02 11:15:16&quot;</td><td>&quot;4 Discretionary Stocks to Buy …</td><td>&quot;https://images.financialmodeli…</td><td>&quot;zacks.com&quot;</td><td>&quot;With inflation cooling and con…</td><td>&quot;https://www.zacks.com/stock/ne…</td></tr><tr><td>&quot;NIO&quot;</td><td>&quot;2025-06-02 11:15:13&quot;</td><td>&quot;NIO&#x27;s May Deliveries Rise 13% …</td><td>&quot;https://images.financialmodeli…</td><td>&quot;zacks.com&quot;</td><td>&quot;NIO delivered over 23K EVs in …</td><td>&quot;https://www.zacks.com/stock/ne…</td></tr><tr><td>&quot;PLTR&quot;</td><td>&quot;2025-06-02 11:15:05&quot;</td><td>&quot;Trump administration expands p…</td><td>&quot;https://images.financialmodeli…</td><td>&quot;proactiveinvestors.com&quot;</td><td>&quot;The Trump administration has s…</td><td>&quot;https://www.proactiveinvestors…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌────────┬──────────────┬──────────────┬──────────────┬──────────────┬──────────────┬──────────────┐\n",
       "│ symbol ┆ publishedDat ┆ title        ┆ image        ┆ site         ┆ text         ┆ url          │\n",
       "│ ---    ┆ e            ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ ---          │\n",
       "│ str    ┆ ---          ┆ str          ┆ str          ┆ str          ┆ str          ┆ str          │\n",
       "│        ┆ str          ┆              ┆              ┆              ┆              ┆              │\n",
       "╞════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╡\n",
       "│ MONRF  ┆ 2025-06-02   ┆ Moncler:     ┆ https://imag ┆ seekingalpha ┆ The DCF      ┆ https://seek │\n",
       "│        ┆ 11:17:33     ┆ Growth, Low  ┆ es.financial ┆ .com         ┆ model        ┆ ingalpha.com │\n",
       "│        ┆              ┆ Debt, And…   ┆ modeli…      ┆              ┆ implemented  ┆ /artic…      │\n",
       "│        ┆              ┆              ┆              ┆              ┆ sugg…        ┆              │\n",
       "│ X      ┆ 2025-06-02   ┆ Jobs Week    ┆ https://imag ┆ zacks.com    ┆ Currently    ┆ https://www. │\n",
       "│        ┆ 11:15:19     ┆ Starts with  ┆ es.financial ┆              ┆ both the     ┆ zacks.com/st │\n",
       "│        ┆              ┆ More Tra…    ┆ modeli…      ┆              ┆ blue-chip D… ┆ ock/ne…      │\n",
       "│ CLCO   ┆ 2025-06-02   ┆ 4 Discretion ┆ https://imag ┆ zacks.com    ┆ With         ┆ https://www. │\n",
       "│        ┆ 11:15:16     ┆ ary Stocks   ┆ es.financial ┆              ┆ inflation    ┆ zacks.com/st │\n",
       "│        ┆              ┆ to Buy …     ┆ modeli…      ┆              ┆ cooling and  ┆ ock/ne…      │\n",
       "│        ┆              ┆              ┆              ┆              ┆ con…         ┆              │\n",
       "│ NIO    ┆ 2025-06-02   ┆ NIO's May    ┆ https://imag ┆ zacks.com    ┆ NIO          ┆ https://www. │\n",
       "│        ┆ 11:15:13     ┆ Deliveries   ┆ es.financial ┆              ┆ delivered    ┆ zacks.com/st │\n",
       "│        ┆              ┆ Rise 13% …   ┆ modeli…      ┆              ┆ over 23K EVs ┆ ock/ne…      │\n",
       "│        ┆              ┆              ┆              ┆              ┆ in …         ┆              │\n",
       "│ PLTR   ┆ 2025-06-02   ┆ Trump admini ┆ https://imag ┆ proactiveinv ┆ The Trump    ┆ https://www. │\n",
       "│        ┆ 11:15:05     ┆ stration     ┆ es.financial ┆ estors.com   ┆ administrati ┆ proactiveinv │\n",
       "│        ┆              ┆ expands p…   ┆ modeli…      ┆              ┆ on has s…    ┆ estors…      │\n",
       "└────────┴──────────────┴──────────────┴──────────────┴──────────────┴──────────────┴──────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get API key from environment variables\n",
    "FMP_API_KEY = 'FMP_API_KEY'\n",
    "\n",
    "# Configuration variables for fetch_data function\n",
    "DAYS_BACK = 7                    # Number of days to look back for news\n",
    "MAX_PAGES = 10                   # Maximum number of pages to fetch\n",
    "RECORDS_PER_PAGE = 1000          # Number of records per page\n",
    "REQUEST_TIMEOUT = 10             # Timeout for API requests in seconds\n",
    "API_BASE_URL = \"https://financialmodelingprep.com/api/v3/stock_news\"\n",
    "DATE_FORMAT = \"%Y-%m-%d %H:%M:%S\"  # Date format for parsing publishedDate\n",
    "\n",
    "# Create session and fetch data with all required parameters\n",
    "session = create_session()\n",
    "data = fetch_data(\n",
    "    api_key=FMP_API_KEY,\n",
    "    session=session,\n",
    "    days_back=30,           # Custom: 30 days back\n",
    "    max_pages=15,           # Custom: 15 pages\n",
    "    records_per_page=1000,  \n",
    "    request_timeout=10      \n",
    ")\n",
    "\n",
    "news_df = pl.DataFrame(data)\n",
    "display(news_df.sort('publishedDate', descending=True).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3949edb",
   "metadata": {},
   "source": [
    "### **Step 3: Sentiment Analysis**\n",
    "- Use `TextBlob` for sentiment analysis on news headlines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1660790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fundamental data...\n",
      "Loaded 504 stocks, 4273 unique tickers\n",
      "Analyzing sentiment for stock symbols...\n",
      "\n",
      "Screened 1697 stocks, 11 sectors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>symbol</th><th>articlesInLastWeek</th><th>companyNewsScore</th><th>bearishPercent</th><th>bullishPercent</th><th>averageSentimentScore</th><th>totalArticles</th><th>sectorAverageBullishPercent</th><th>sectorAverageNewsScore</th><th>sector</th><th>marketCap</th><th>peRatio</th><th>price</th></tr><tr><td>str</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;BGM&quot;</td><td>4</td><td>0.9</td><td>0.0</td><td>1.0</td><td>0.8</td><td>4</td><td>0.0</td><td>0.0</td><td>&quot;Unknown&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;LPCN&quot;</td><td>4</td><td>0.8</td><td>0.0</td><td>1.0</td><td>0.6</td><td>4</td><td>0.0</td><td>0.0</td><td>&quot;Unknown&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;CAE&quot;</td><td>4</td><td>0.8</td><td>0.0</td><td>1.0</td><td>0.6</td><td>4</td><td>0.0</td><td>0.0</td><td>&quot;Unknown&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;NSCIF&quot;</td><td>3</td><td>0.7803</td><td>0.0</td><td>1.0</td><td>0.5606</td><td>3</td><td>0.0</td><td>0.0</td><td>&quot;Unknown&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;HBFG&quot;</td><td>5</td><td>0.7788</td><td>0.0</td><td>1.0</td><td>0.5576</td><td>5</td><td>0.0</td><td>0.0</td><td>&quot;Unknown&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 13)\n",
       "┌────────┬───────────────┬──────────────┬──────────────┬───┬─────────┬───────────┬─────────┬───────┐\n",
       "│ symbol ┆ articlesInLas ┆ companyNewsS ┆ bearishPerce ┆ … ┆ sector  ┆ marketCap ┆ peRatio ┆ price │\n",
       "│ ---    ┆ tWeek         ┆ core         ┆ nt           ┆   ┆ ---     ┆ ---       ┆ ---     ┆ ---   │\n",
       "│ str    ┆ ---           ┆ ---          ┆ ---          ┆   ┆ str     ┆ f64       ┆ f64     ┆ f64   │\n",
       "│        ┆ i64           ┆ f64          ┆ f64          ┆   ┆         ┆           ┆         ┆       │\n",
       "╞════════╪═══════════════╪══════════════╪══════════════╪═══╪═════════╪═══════════╪═════════╪═══════╡\n",
       "│ BGM    ┆ 4             ┆ 0.9          ┆ 0.0          ┆ … ┆ Unknown ┆ 0.0       ┆ 0.0     ┆ 0.0   │\n",
       "│ LPCN   ┆ 4             ┆ 0.8          ┆ 0.0          ┆ … ┆ Unknown ┆ 0.0       ┆ 0.0     ┆ 0.0   │\n",
       "│ CAE    ┆ 4             ┆ 0.8          ┆ 0.0          ┆ … ┆ Unknown ┆ 0.0       ┆ 0.0     ┆ 0.0   │\n",
       "│ NSCIF  ┆ 3             ┆ 0.7803       ┆ 0.0          ┆ … ┆ Unknown ┆ 0.0       ┆ 0.0     ┆ 0.0   │\n",
       "│ HBFG   ┆ 5             ┆ 0.7788       ┆ 0.0          ┆ … ┆ Unknown ┆ 0.0       ┆ 0.0     ┆ 0.0   │\n",
       "└────────┴───────────────┴──────────────┴──────────────┴───┴─────────┴───────────┴─────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (11, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>sector</th><th>stock_count</th><th>avg_news_score</th><th>avg_bullish_percent</th><th>avg_articles</th><th>avg_market_cap</th><th>avg_pe_ratio</th></tr><tr><td>str</td><td>u32</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Utilities&quot;</td><td>28</td><td>0.589464</td><td>0.582643</td><td>17.035714</td><td>4.2542e10</td><td>21.169643</td></tr><tr><td>&quot;Communication Services&quot;</td><td>19</td><td>0.583947</td><td>0.591137</td><td>27.263158</td><td>3.9771e11</td><td>NaN</td></tr><tr><td>&quot;Healthcare&quot;</td><td>52</td><td>0.571731</td><td>0.530044</td><td>20.230769</td><td>8.9752e10</td><td>NaN</td></tr><tr><td>&quot;Technology&quot;</td><td>77</td><td>0.569574</td><td>0.52053</td><td>17.0</td><td>2.1666e11</td><td>NaN</td></tr><tr><td>&quot;Consumer Cyclical&quot;</td><td>51</td><td>0.566929</td><td>0.507137</td><td>12.45098</td><td>1.1478e11</td><td>NaN</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Industrials&quot;</td><td>62</td><td>0.561069</td><td>0.471273</td><td>10.5</td><td>5.9014e10</td><td>NaN</td></tr><tr><td>&quot;Energy&quot;</td><td>21</td><td>0.559405</td><td>0.389214</td><td>6.333333</td><td>7.0332e10</td><td>NaN</td></tr><tr><td>&quot;Real Estate&quot;</td><td>28</td><td>0.559225</td><td>0.426325</td><td>8.5</td><td>3.6466e10</td><td>NaN</td></tr><tr><td>&quot;Financial Services&quot;</td><td>59</td><td>0.551597</td><td>0.390469</td><td>11.949153</td><td>1.0424e11</td><td>NaN</td></tr><tr><td>&quot;Basic Materials&quot;</td><td>18</td><td>0.542856</td><td>0.434572</td><td>6.055556</td><td>3.5205e10</td><td>NaN</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (11, 7)\n",
       "┌──────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┐\n",
       "│ sector       ┆ stock_count ┆ avg_news_sc ┆ avg_bullish ┆ avg_article ┆ avg_market_ ┆ avg_pe_rati │\n",
       "│ ---          ┆ ---         ┆ ore         ┆ _percent    ┆ s           ┆ cap         ┆ o           │\n",
       "│ str          ┆ u32         ┆ ---         ┆ ---         ┆ ---         ┆ ---         ┆ ---         │\n",
       "│              ┆             ┆ f64         ┆ f64         ┆ f64         ┆ f64         ┆ f64         │\n",
       "╞══════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╡\n",
       "│ Utilities    ┆ 28          ┆ 0.589464    ┆ 0.582643    ┆ 17.035714   ┆ 4.2542e10   ┆ 21.169643   │\n",
       "│ Communicatio ┆ 19          ┆ 0.583947    ┆ 0.591137    ┆ 27.263158   ┆ 3.9771e11   ┆ NaN         │\n",
       "│ n Services   ┆             ┆             ┆             ┆             ┆             ┆             │\n",
       "│ Healthcare   ┆ 52          ┆ 0.571731    ┆ 0.530044    ┆ 20.230769   ┆ 8.9752e10   ┆ NaN         │\n",
       "│ Technology   ┆ 77          ┆ 0.569574    ┆ 0.52053     ┆ 17.0        ┆ 2.1666e11   ┆ NaN         │\n",
       "│ Consumer     ┆ 51          ┆ 0.566929    ┆ 0.507137    ┆ 12.45098    ┆ 1.1478e11   ┆ NaN         │\n",
       "│ Cyclical     ┆             ┆             ┆             ┆             ┆             ┆             │\n",
       "│ …            ┆ …           ┆ …           ┆ …           ┆ …           ┆ …           ┆ …           │\n",
       "│ Industrials  ┆ 62          ┆ 0.561069    ┆ 0.471273    ┆ 10.5        ┆ 5.9014e10   ┆ NaN         │\n",
       "│ Energy       ┆ 21          ┆ 0.559405    ┆ 0.389214    ┆ 6.333333    ┆ 7.0332e10   ┆ NaN         │\n",
       "│ Real Estate  ┆ 28          ┆ 0.559225    ┆ 0.426325    ┆ 8.5         ┆ 3.6466e10   ┆ NaN         │\n",
       "│ Financial    ┆ 59          ┆ 0.551597    ┆ 0.390469    ┆ 11.949153   ┆ 1.0424e11   ┆ NaN         │\n",
       "│ Services     ┆             ┆             ┆             ┆             ┆             ┆             │\n",
       "│ Basic        ┆ 18          ┆ 0.542856    ┆ 0.434572    ┆ 6.055556    ┆ 3.5205e10   ┆ NaN         │\n",
       "│ Materials    ┆             ┆             ┆             ┆             ┆             ┆             │\n",
       "└──────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from py.sentiment_analysis import calculate_stock_sentiment_metrics, get_fundamental_value, calculate_sector_averages\n",
    "\n",
    "# Load fundamental data and prepare ticker lists\n",
    "print(\"Loading fundamental data...\")\n",
    "fundamentals_df = pl.read_csv('data/fundamentals_stock.csv')\n",
    "fundamentals_pandas = fundamentals_df.to_pandas().set_index('Ticker')\n",
    "all_tickers = set(news_df['symbol'].to_list() + fundamentals_df['Ticker'].to_list())\n",
    "EXCLUDED_SYMBOLS = {'AI', 'S', 'A', 'U', 'E', 'US', 'ET', 'TSXV', 'CODI', 'C'}\n",
    "\n",
    "print(f\"Loaded {len(fundamentals_df)} stocks, {len(all_tickers)} unique tickers\")\n",
    "\n",
    "# Execute sentiment analysis\n",
    "print(\"Analyzing sentiment for stock symbols...\")\n",
    "sentiment_metrics = calculate_stock_sentiment_metrics(news_df, all_tickers, EXCLUDED_SYMBOLS)\n",
    "sentiment_df = pl.DataFrame([{\n",
    "    \"symbol\": symbol, \"articlesInLastWeek\": metrics[\"articlesInLastWeek\"],\n",
    "    \"companyNewsScore\": metrics[\"companyNewsScore\"], \n",
    "    \"bearishPercent\": metrics[\"sentiment\"][\"bearishPercent\"],\n",
    "    \"bullishPercent\": metrics[\"sentiment\"][\"bullishPercent\"],\n",
    "    \"averageSentimentScore\": metrics[\"averageSentimentScore\"],\n",
    "    \"totalArticles\": metrics[\"totalArticles\"]\n",
    "} for symbol, metrics in sentiment_metrics.items()]).sort([\"articlesInLastWeek\", \"companyNewsScore\"], descending=[True, True])\n",
    "\n",
    "# Add fundamental data and sector averages\n",
    "sector_averages = calculate_sector_averages(sentiment_df, fundamentals_pandas)\n",
    "sentiment_with_fundamentals = sentiment_df.with_columns([\n",
    "    pl.col(\"symbol\").map_elements(lambda x: sector_averages.get(get_fundamental_value(x, 'Sector', 'Unknown'), {}).get('sectorAverageBullishPercent', 0), return_dtype=pl.Float64).alias(\"sectorAverageBullishPercent\"),\n",
    "    pl.col(\"symbol\").map_elements(lambda x: sector_averages.get(get_fundamental_value(x, 'Sector', 'Unknown'), {}).get('sectorAverageNewsScore', 0), return_dtype=pl.Float64).alias(\"sectorAverageNewsScore\"),\n",
    "    pl.col(\"symbol\").map_elements(lambda x: get_fundamental_value(x, 'Sector', 'Unknown'), return_dtype=pl.Utf8).alias(\"sector\"),\n",
    "    pl.col(\"symbol\").map_elements(lambda x: get_fundamental_value(x, 'Market Cap'), return_dtype=pl.Float64).alias(\"marketCap\"),\n",
    "    pl.col(\"symbol\").map_elements(lambda x: get_fundamental_value(x, 'P/E (trailing)'), return_dtype=pl.Float64).alias(\"peRatio\"),\n",
    "    pl.col(\"symbol\").map_elements(lambda x: get_fundamental_value(x, 'Price'), return_dtype=pl.Float64).alias(\"price\")\n",
    "])\n",
    "\n",
    "# Screen stocks and analyze sectors\n",
    "comprehensive_screened = sentiment_with_fundamentals.filter((pl.col(\"articlesInLastWeek\") >= 3) & (pl.col(\"companyNewsScore\") >= 0.45)).sort([\"companyNewsScore\", \"articlesInLastWeek\"], descending=[True, True])\n",
    "sector_summary = sentiment_with_fundamentals.filter(pl.col(\"sector\") != \"Unknown\").group_by(\"sector\").agg([\n",
    "    pl.count(\"symbol\").alias(\"stock_count\"), pl.mean(\"companyNewsScore\").alias(\"avg_news_score\"),\n",
    "    pl.mean(\"bullishPercent\").alias(\"avg_bullish_percent\"), pl.mean(\"articlesInLastWeek\").alias(\"avg_articles\"),\n",
    "    pl.mean(\"marketCap\").alias(\"avg_market_cap\"), pl.mean(\"peRatio\").alias(\"avg_pe_ratio\")\n",
    "]).sort(\"avg_news_score\", descending=True)\n",
    "\n",
    "print(f\"\\nScreened {len(comprehensive_screened)} stocks, {len(sector_averages)} sectors\")\n",
    "display(comprehensive_screened.head())\n",
    "display(sector_summary)\n",
    "\n",
    "# Export results\n",
    "# sentiment_with_fundamentals.write_csv(\"data/combined_sentiment_fundamentals.csv\")\n",
    "# comprehensive_screened.write_csv(\"data/screened_stocks.csv\")\n",
    "# print(\"Files saved: combined_sentiment_fundamentals.csv and screened_stocks.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a71d85",
   "metadata": {},
   "source": [
    "### **Step 4: Select Top 100 stocks (by `averageSentimentScore`)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5b277a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected 100 stocks with highest sentiment scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>symbol</th><th>articlesInLastWeek</th><th>companyNewsScore</th><th>bearishPercent</th><th>bullishPercent</th><th>averageSentimentScore</th><th>totalArticles</th><th>sectorAverageBullishPercent</th><th>sectorAverageNewsScore</th><th>sector</th><th>marketCap</th><th>peRatio</th><th>price</th></tr><tr><td>str</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;BBY&quot;</td><td>24</td><td>0.7785</td><td>0.0</td><td>1.0</td><td>0.5571</td><td>24</td><td>0.5071</td><td>0.5669</td><td>&quot;Consumer Cyclical&quot;</td><td>1.4031e10</td><td>16.17</td><td>66.28</td></tr><tr><td>&quot;CHTR&quot;</td><td>5</td><td>0.71</td><td>0.0</td><td>0.8</td><td>0.42</td><td>5</td><td>0.5911</td><td>0.5839</td><td>&quot;Communication Services&quot;</td><td>5.4738e10</td><td>11.06</td><td>396.27</td></tr><tr><td>&quot;NXPI&quot;</td><td>4</td><td>0.7</td><td>0.0</td><td>0.5</td><td>0.4</td><td>4</td><td>0.5205</td><td>0.5696</td><td>&quot;Technology&quot;</td><td>4.8285e10</td><td>20.84</td><td>191.13</td></tr><tr><td>&quot;ZTS&quot;</td><td>5</td><td>0.6844</td><td>0.0</td><td>1.0</td><td>0.3689</td><td>5</td><td>0.53</td><td>0.5717</td><td>&quot;Healthcare&quot;</td><td>7.5075e10</td><td>30.33</td><td>168.63</td></tr><tr><td>&quot;FI&quot;</td><td>6</td><td>0.67</td><td>0.0</td><td>0.6667</td><td>0.3401</td><td>6</td><td>0.5205</td><td>0.5696</td><td>&quot;Technology&quot;</td><td>9.0256e10</td><td>28.81</td><td>162.79</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 13)\n",
       "┌────────┬─────────────┬─────────────┬─────────────┬───┬────────────┬───────────┬─────────┬────────┐\n",
       "│ symbol ┆ articlesInL ┆ companyNews ┆ bearishPerc ┆ … ┆ sector     ┆ marketCap ┆ peRatio ┆ price  │\n",
       "│ ---    ┆ astWeek     ┆ Score       ┆ ent         ┆   ┆ ---        ┆ ---       ┆ ---     ┆ ---    │\n",
       "│ str    ┆ ---         ┆ ---         ┆ ---         ┆   ┆ str        ┆ f64       ┆ f64     ┆ f64    │\n",
       "│        ┆ i64         ┆ f64         ┆ f64         ┆   ┆            ┆           ┆         ┆        │\n",
       "╞════════╪═════════════╪═════════════╪═════════════╪═══╪════════════╪═══════════╪═════════╪════════╡\n",
       "│ BBY    ┆ 24          ┆ 0.7785      ┆ 0.0         ┆ … ┆ Consumer   ┆ 1.4031e10 ┆ 16.17   ┆ 66.28  │\n",
       "│        ┆             ┆             ┆             ┆   ┆ Cyclical   ┆           ┆         ┆        │\n",
       "│ CHTR   ┆ 5           ┆ 0.71        ┆ 0.0         ┆ … ┆ Communicat ┆ 5.4738e10 ┆ 11.06   ┆ 396.27 │\n",
       "│        ┆             ┆             ┆             ┆   ┆ ion        ┆           ┆         ┆        │\n",
       "│        ┆             ┆             ┆             ┆   ┆ Services   ┆           ┆         ┆        │\n",
       "│ NXPI   ┆ 4           ┆ 0.7         ┆ 0.0         ┆ … ┆ Technology ┆ 4.8285e10 ┆ 20.84   ┆ 191.13 │\n",
       "│ ZTS    ┆ 5           ┆ 0.6844      ┆ 0.0         ┆ … ┆ Healthcare ┆ 7.5075e10 ┆ 30.33   ┆ 168.63 │\n",
       "│ FI     ┆ 6           ┆ 0.67        ┆ 0.0         ┆ … ┆ Technology ┆ 9.0256e10 ┆ 28.81   ┆ 162.79 │\n",
       "└────────┴─────────────┴─────────────┴─────────────┴───┴────────────┴───────────┴─────────┴────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sector distribution:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>sector</th><th>stock_count</th><th>avg_sentiment_score</th><th>avg_news_score</th><th>avg_bullish_percent</th></tr><tr><td>str</td><td>u32</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Technology&quot;</td><td>19</td><td>0.248995</td><td>0.624479</td><td>0.698784</td></tr><tr><td>&quot;Industrials&quot;</td><td>17</td><td>0.231253</td><td>0.615629</td><td>0.742094</td></tr><tr><td>&quot;Consumer Cyclical&quot;</td><td>13</td><td>0.256838</td><td>0.628408</td><td>0.717069</td></tr><tr><td>&quot;Utilities&quot;</td><td>13</td><td>0.247046</td><td>0.623523</td><td>0.677785</td></tr><tr><td>&quot;Healthcare&quot;</td><td>11</td><td>0.233018</td><td>0.6165</td><td>0.756909</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌───────────────────┬─────────────┬─────────────────────┬────────────────┬─────────────────────┐\n",
       "│ sector            ┆ stock_count ┆ avg_sentiment_score ┆ avg_news_score ┆ avg_bullish_percent │\n",
       "│ ---               ┆ ---         ┆ ---                 ┆ ---            ┆ ---                 │\n",
       "│ str               ┆ u32         ┆ f64                 ┆ f64            ┆ f64                 │\n",
       "╞═══════════════════╪═════════════╪═════════════════════╪════════════════╪═════════════════════╡\n",
       "│ Technology        ┆ 19          ┆ 0.248995            ┆ 0.624479       ┆ 0.698784            │\n",
       "│ Industrials       ┆ 17          ┆ 0.231253            ┆ 0.615629       ┆ 0.742094            │\n",
       "│ Consumer Cyclical ┆ 13          ┆ 0.256838            ┆ 0.628408       ┆ 0.717069            │\n",
       "│ Utilities         ┆ 13          ┆ 0.247046            ┆ 0.623523       ┆ 0.677785            │\n",
       "│ Healthcare        ┆ 11          ┆ 0.233018            ┆ 0.6165         ┆ 0.756909            │\n",
       "└───────────────────┴─────────────┴─────────────────────┴────────────────┴─────────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary statistics for selected stocks:\n",
      "Average sentiment score: 0.2430\n",
      "Min sentiment score: 0.1737\n",
      "Max sentiment score: 0.5571\n",
      "Average company news score: 0.6215\n",
      "Number of stocks: 100\n",
      "Number of unique sectors: 11\n"
     ]
    }
   ],
   "source": [
    "selected_stocks = (comprehensive_screened\n",
    "    .filter(pl.col(\"sector\") != 'Unknown')\n",
    "    .sort(\"averageSentimentScore\", descending=True)\n",
    "    .head(100))\n",
    "\n",
    "screened_tickers = selected_stocks['symbol'].to_list()\n",
    "print(f\"\\nSelected {len(screened_tickers)} stocks with highest sentiment scores\")\n",
    "display(selected_stocks.head())\n",
    "\n",
    "# Sector distribution and summary statistics\n",
    "sector_distribution = selected_stocks.group_by(\"sector\").agg([\n",
    "    pl.count(\"symbol\").alias(\"stock_count\"),\n",
    "    pl.mean(\"averageSentimentScore\").alias(\"avg_sentiment_score\"),\n",
    "    pl.mean(\"companyNewsScore\").alias(\"avg_news_score\"),\n",
    "    pl.mean(\"bullishPercent\").alias(\"avg_bullish_percent\")\n",
    "]).sort(\"stock_count\", descending=True)\n",
    "\n",
    "print(f\"\\nSector distribution:\")\n",
    "display(sector_distribution.head())\n",
    "\n",
    "# Show summary statistics\n",
    "print(f\"\\nSummary statistics for selected stocks:\")\n",
    "print(f\"Average sentiment score: {selected_stocks['averageSentimentScore'].mean():.4f}\")\n",
    "print(f\"Min sentiment score: {selected_stocks['averageSentimentScore'].min():.4f}\")\n",
    "print(f\"Max sentiment score: {selected_stocks['averageSentimentScore'].max():.4f}\")\n",
    "print(f\"Average company news score: {selected_stocks['companyNewsScore'].mean():.4f}\")\n",
    "print(f\"Number of stocks: {selected_stocks['symbol'].count()}\")\n",
    "print(f\"Number of unique sectors: {selected_stocks['sector'].n_unique()}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
